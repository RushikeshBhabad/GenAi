{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3C+Z10zFjyW+sy+JJZrtu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RushikeshBhabad/GenAi/blob/main/AI_Agents_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOrRhjisRBO6",
        "outputId": "f4eb2737-7c42-4b74-ccb5-3cb2ab5d0736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.33-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-llms-groq\n",
            "  Downloading llama_index_llms_groq-0.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.33 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.33.post1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Collecting llama-index-llms-openai-like<0.4.0,>=0.3.1 (from llama-index-llms-groq)\n",
            "  Downloading llama_index_llms_openai_like-0.3.4-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.75.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.33->llama-index) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (3.11.15)\n",
            "Collecting banks<3.0.0,>=2.0.0 (from llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (2.11.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (9.1.2)\n",
            "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (4.13.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.18-py3-none-any.whl.metadata (902 bytes)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (4.51.3)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.12-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.33->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.33->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.33->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.33->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.33->llama-index) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.33->llama-index) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.33->llama-index) (1.19.0)\n",
            "Collecting griffe (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama-index) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama-index) (4.3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.33->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.33->llama-index) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.33->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.33->llama-index) (0.14.0)\n",
            "Collecting llama-cloud-services>=0.6.12 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.15-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.33->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.33->llama-index) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.33->llama-index) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.33->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.33->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.33->llama-index) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.5.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.2)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.12->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama-index) (3.0.2)\n",
            "Downloading llama_index-0.12.33-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_llms_groq-0.3.1-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.33.post1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
            "Downloading llama_index_llms_openai_like-0.3.4-py3-none-any.whl (4.3 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_cloud-0.1.18-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.12-py3-none-any.whl (4.9 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_cloud_services-0.6.15-py3-none-any.whl (36 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, python-dotenv, pypdf, mypy-extensions, marshmallow, colorama, typing-inspect, tiktoken, griffe, llama-cloud, dataclasses-json, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-openai-like, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-llms-groq, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed banks-2.1.2 colorama-0.4.6 dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.7.3 llama-cloud-0.1.18 llama-cloud-services-0.6.15 llama-index-0.12.33 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.33.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-groq-0.3.1 llama-index-llms-openai-0.3.38 llama-index-llms-openai-like-0.3.4 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.12 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-5.4.0 python-dotenv-1.1.0 striprtf-0.0.26 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama-index-llms-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.core.tools import FunctionTool"
      ],
      "metadata": {
        "id": "TyJLs3suRPUz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "k182EH1BRRvS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Groq(\n",
        "    model = \"llama3-70b-8192\",\n",
        "    temperature = 0\n",
        ")"
      ],
      "metadata": {
        "id": "0unYs0udSXDh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating basic arithmetic tools**"
      ],
      "metadata": {
        "id": "uhl0Jfd9S0Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add(a: float, b: float) -> float:\n",
        "  \"\"\"Add two numbers and return the sum.\"\"\"\n",
        "  return a + b\n",
        "\n",
        "\n",
        "def subtract(a: float, b: float) -> float:\n",
        "  \"\"\"Subtract the second number from the first number and return the result\"\"\"\n",
        "  return a - b\n",
        "\n",
        "def multiply(a: float, b: float) -> float:\n",
        "  \"\"\"Multiply twi numbers abd return teh product\"\"\"\n",
        "  return a * b\n",
        "\n",
        "def devide(a: float, b: float) -> float:\n",
        "  \"\"\"Divide the first number by the second number and return teh quotient\"\"\"\n",
        "  return a / b"
      ],
      "metadata": {
        "id": "BUevcvy_SrWE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "subtract_tool = FunctionTool.from_defaults(fn=subtract)\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "divide_tool = FunctionTool.from_defaults(fn=devide)"
      ],
      "metadata": {
        "id": "EgfBygNeTalG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools_list = [add_tool, subtract_tool, multiply_tool, divide_tool]"
      ],
      "metadata": {
        "id": "WVn1z_dmT70W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the agent**"
      ],
      "metadata": {
        "id": "34I3pTXZUW_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools(\n",
        "    tools_list,\n",
        "    llm = llm,\n",
        "    verbose = True # HELPFUL for debugging\n",
        ")"
      ],
      "metadata": {
        "id": "DmrQKcXxUP6v"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agent in action**"
      ],
      "metadata": {
        "id": "fWMG_8tFUWaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"What is 20 multiply by 2? who owner of mumbai indians in hindi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtxOnREGVL25",
        "outputId": "d8fec908-b1fe-4acd-f28b-9dd6e9295675"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 68c56273-f8c2-45e2-9c9c-04c9306c1a17. Step input: What is 20 multiply by 2? who owner of mumbai indians in hindi\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: Hindi. I need to use a tool to help me answer the question.\n",
            "Action: multiply\n",
            "Action Input: {'a': 20, 'b': 2}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 40\n",
            "\u001b[0m> Running step dd2f5474-66ab-4e89-9dc5-eb0960e4aedf. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have the result of the multiplication, now I need to answer the second part of the question.\n",
            "Answer: मुकेश अम्बानी मुम्बई इंडियन्स के मालिक हैं।\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2JLVtKSVRH6",
        "outputId": "13a40ab4-6278-4694-8faf-ada55ed45d2b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentChatResponse(response='मुकेश अम्बानी मुम्बई इंडियन्स के मालिक हैं।', sources=[ToolOutput(content='40', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 20, 'b': 2}}, raw_output=40, is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhtRmP0dVvZV",
        "outputId": "375e70ea-52ef-48ce-aa68-5e8f612e5948"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "मुकेश अम्बानी मुम्बई इंडियन्स के मालिक हैं।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_output_value = response.sources[0].raw_output\n",
        "print(raw_output_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7RKlhBzV6qm",
        "outputId": "7090405f-540d-43a3-ad23-f1cd65d16997"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"What is (20+2*5)*2 use tools give answer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOA7twR5WQuC",
        "outputId": "9b3b9d50-e4e3-40ec-90ab-2474517b682c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 82f00721-f4f1-48f7-b419-fc89ec5e6dbc. Step input: What is (20+2*5)*2 use tools give answer\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: multiply\n",
            "Action Input: {'a': 2, 'b': 5}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 10\n",
            "\u001b[0m> Running step cc2d04a9-d532-4f76-b2ff-6966aed71137. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Now I need to add 20 to the result.\n",
            "Action: add\n",
            "Action Input: {'a': 20, 'b': 10}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 30\n",
            "\u001b[0m> Running step c50be5dc-c856-4468-804a-fb790751a5b3. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Now I need to multiply the result by 2.\n",
            "Action: multiply\n",
            "Action Input: {'a': 30, 'b': 2}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 60\n",
            "\u001b[0m> Running step ec1733b2-8845-4d45-b8f3-e491a2515acf. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: 60\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBigNa6LWuQX",
        "outputId": "0c93c1c2-d000-4aab-a147-3c3f8e8db631"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fp8HClf3W8cm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}